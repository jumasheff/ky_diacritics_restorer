{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kyrgyz Diacritics Restorer - Training Notebook\n",
    "\n",
    "This notebook trains a sequence-to-sequence model to restore diacritics in Kyrgyz text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/jumasheff/ky_diacritics_restorer.git\n",
    "%cd ky_diacritics_restorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KyrgyzTextDataset(Dataset):\n",
    "    pad_idx = None  # This will be set in __init__\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.input_texts = []\n",
    "        self.target_texts = []\n",
    "        \n",
    "        # Create character to index mappings\n",
    "        self.char_to_idx = {}\n",
    "        self.idx_to_char = {}\n",
    "        \n",
    "        # Read data and build vocabulary\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            next(f)  # Skip header\n",
    "            for line in f:\n",
    "                if '\\t' in line:\n",
    "                    fields = line.strip().split('\\t')\n",
    "                    if len(fields) >= 2:\n",
    "                        target = fields[1].strip()\n",
    "                        input_text = fields[2].strip() if len(fields) > 2 else target\n",
    "                        self.input_texts.append(input_text)\n",
    "                        self.target_texts.append(target)\n",
    "                        \n",
    "                        # Update vocabulary\n",
    "                        for char in input_text + target:\n",
    "                            if char not in self.char_to_idx:\n",
    "                                idx = len(self.char_to_idx)\n",
    "                                self.char_to_idx[char] = idx\n",
    "                                self.idx_to_char[idx] = char\n",
    "        \n",
    "        self.vocab_size = len(self.char_to_idx)\n",
    "        self.pad_idx = self.vocab_size\n",
    "        KyrgyzTextDataset.pad_idx = self.vocab_size\n",
    "        self.char_to_idx['<PAD>'] = self.pad_idx\n",
    "        self.idx_to_char[self.pad_idx] = '<PAD>'\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_text = self.input_texts[idx]\n",
    "        target_text = self.target_texts[idx]\n",
    "        \n",
    "        # Convert to indices\n",
    "        input_indices = [self.char_to_idx[c] for c in input_text]\n",
    "        target_indices = [self.char_to_idx[c] for c in target_text]\n",
    "        \n",
    "        return torch.tensor(input_indices, dtype=torch.long), torch.tensor(target_indices, dtype=torch.long)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        # Separate inputs and targets\n",
    "        inputs, targets = zip(*batch)\n",
    "        \n",
    "        # Get max lengths\n",
    "        input_lengths = [len(x) for x in inputs]\n",
    "        target_lengths = [len(x) for x in targets]\n",
    "        max_input_len = max(input_lengths)\n",
    "        max_target_len = max(target_lengths)\n",
    "        \n",
    "        # Pad sequences\n",
    "        padded_inputs = torch.full((len(batch), max_input_len), KyrgyzTextDataset.pad_idx, dtype=torch.long)\n",
    "        padded_targets = torch.full((len(batch), max_target_len), KyrgyzTextDataset.pad_idx, dtype=torch.long)\n",
    "        \n",
    "        for i, (input, target) in enumerate(zip(inputs, targets)):\n",
    "            padded_inputs[i, :len(input)] = input\n",
    "            padded_targets[i, :len(target)] = target\n",
    "        \n",
    "        return padded_inputs, padded_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)  # +1 for padding\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)  # +1 for padding\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size + 1)  # +1 for padding\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "        \n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        \n",
    "        # First decoder input is first target token\n",
    "        decoder_input = trg[:, 0]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            decoder_input = trg[:, t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        src, trg = batch\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # Reshape output and target for loss calculation\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].contiguous().view(-1, output_dim)  # Skip first token\n",
    "        trg = trg[:, 1:].contiguous().view(-1)  # Skip first token\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(train_loader)\n",
    "\n",
    "def restore_diacritics(model, text, dataset, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Convert input text to indices\n",
    "        input_indices = [dataset.char_to_idx[c] for c in text]\n",
    "        src = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Initialize output with first character\n",
    "        output_chars = [text[0]]\n",
    "        decoder_input = src[:, 0]\n",
    "        \n",
    "        # Get encoder outputs\n",
    "        encoder_outputs, hidden, cell = model.encoder(src)\n",
    "        \n",
    "        # Generate rest of the sequence\n",
    "        max_length = len(text) * 2  # Prevent infinite loop while allowing for extra diacritics\n",
    "        \n",
    "        for t in range(1, max_length):\n",
    "            # Get decoder output\n",
    "            output, hidden, cell = model.decoder(decoder_input, hidden, cell)\n",
    "            \n",
    "            # Get best prediction and add to output\n",
    "            top1 = output.argmax(1)\n",
    "            pred_char = dataset.idx_to_char[top1.item()]\n",
    "            \n",
    "            # Add prediction to output\n",
    "            output_chars.append(pred_char)\n",
    "            \n",
    "            # Use prediction as next input\n",
    "            decoder_input = top1\n",
    "            \n",
    "            # Stop if we've generated enough characters\n",
    "            if len(output_chars) >= len(text) and pred_char in {'.', '!', '?'}:\n",
    "                break\n",
    "                \n",
    "    return ''.join(output_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Load dataset\n",
    "dataset = KyrgyzTextDataset('example_dataset.tsv')\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=KyrgyzTextDataset.collate_fn)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Vocabulary size: {dataset.vocab_size}\")\n",
    "\n",
    "# Initialize model\n",
    "encoder = Encoder(dataset.vocab_size + 1, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
    "decoder = Decoder(dataset.vocab_size + 1, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=dataset.pad_idx)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm(range(N_EPOCHS), desc=\"Training\"):\n",
    "    loss = train_model(model, train_loader, optimizer, criterion, device)\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss:.4f}')\n",
    "    \n",
    "    # Save best model\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f'Model saved with loss: {best_loss:.4f}')\n",
    "    \n",
    "    # Test the model every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        test_sentences = [\n",
    "            \"Менин уйум чон.\",\n",
    "            \"Кочодо коп машина бар.\",\n",
    "            \"Бугун кун ысык.\"\n",
    "        ]\n",
    "        print(\"\\nTesting examples:\")\n",
    "        with torch.no_grad():\n",
    "            for sent in test_sentences:\n",
    "                restored = restore_diacritics(model, sent, dataset, device)\n",
    "                print(f'Input: {sent}')\n",
    "                print(f'Output: {restored}\\n')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
